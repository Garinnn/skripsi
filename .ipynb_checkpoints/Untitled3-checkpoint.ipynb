{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea849986-68b6-43f0-a250-600af2e6a397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Library berhasil diimport.\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 1: Import Library =====\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Handling imbalance\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Save model\n",
    "import joblib\n",
    "\n",
    "print(\"âœ… Library berhasil diimport.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48c75b4c-40ed-42de-870a-847e33b05d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset berhasil digabung,\n",
      "Ukuran dataset gabungan: (14380, 2)\n",
      "                                              Narasi  hoax\n",
      "0  Anies di Milad BKMT: Pengajian Menghasilkan Ib...     0\n",
      "1  Edy Soal Pilgub Sumut: Kalau yang Maju Abal-ab...     0\n",
      "2  PKB Bakal Daftarkan Menaker Ida Fauziyah Jadi ...     0\n",
      "3  Gede Pasek Doakan AHY Jadi Capres atau Cawapre...     0\n",
      "4  PKN Siapkan Jabatan Khusus Buat Anas Urbaningr...     0\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 2: Load Dataset =====\n",
    "\n",
    "# Load dataset\n",
    "data1 = pd.read_csv(\"dataset_cnn_10k_cleaned.csv\")\n",
    "data2 = pd.read_csv(\"dataset_kompas_4k_cleaned.csv\")\n",
    "\n",
    "# Ambil kolom teks & label, samakan nama ke \"Narasi\" dan \"hoax\"\n",
    "d1 = data1[['text_new', 'hoax']].rename(columns={'text_new':'Narasi'})\n",
    "d2 = data2[['text_new', 'hoax']].rename(columns={'text_new':'Narasi'})\n",
    "\n",
    "# Gabungkan dataset\n",
    "data = pd.concat([d1, d2], ignore_index=True)\n",
    "\n",
    "print(\"âœ… Dataset berhasil digabung,\")\n",
    "print(\"Ukuran dataset gabungan:\", data.shape)\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "565d254c-4d22-4298-b93f-51a976babb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [39:59<00:00, 299.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Preprocessing selesai!\n",
      "                                              Narasi  \\\n",
      "0  Anies di Milad BKMT: Pengajian Menghasilkan Ib...   \n",
      "1  Edy Soal Pilgub Sumut: Kalau yang Maju Abal-ab...   \n",
      "2  PKB Bakal Daftarkan Menaker Ida Fauziyah Jadi ...   \n",
      "3  Gede Pasek Doakan AHY Jadi Capres atau Cawapre...   \n",
      "4  PKN Siapkan Jabatan Khusus Buat Anas Urbaningr...   \n",
      "\n",
      "                                          clean_text  hoax  \n",
      "0  anies milad bkmt aji hasil ibu ibu tahu mantan...     0  \n",
      "1  edy soal pilgub sumut kalau maju abal abal pak...     0  \n",
      "2  pkb bakal daftar menaker ida fauziyah jadi cal...     0  \n",
      "3  gede pasek doa ahy jadi capres cawapres ketua ...     0  \n",
      "4  pkn siap jabat khusus buat anas urbaningrum us...     0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 3: Preprocessing =====\n",
    "import re\n",
    "import pandas as pd\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Setup stemmer & stopwords\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "stop_factory = StopWordRemoverFactory()\n",
    "extra_stopwords = [\"dengan\",\"bahwa\",\"karena\",\"sudah\",\"juga\",\"akan\",\"untuk\"]\n",
    "stop_words = set(stop_factory.get_stop_words() + extra_stopwords)\n",
    "\n",
    "# Cache buat stemming biar ga ngulang-ngulang\n",
    "stem_cache = {}\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    s = text.lower()\n",
    "    s = re.sub(r\"http\\S+|www\\S+\", \" \", s)   # hapus URL\n",
    "    s = re.sub(r\"[^a-zA-Z\\s]\", \" \", s)      # hapus angka & simbol\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()      # hapus spasi ganda\n",
    "    \n",
    "    tokens = [w for w in s.split() if w not in stop_words]\n",
    "    tokens = [stem_cache[w] if w in stem_cache else stemmer.stem(w) for w in tokens]\n",
    "    for w in tokens:\n",
    "        if w not in stem_cache:\n",
    "            stem_cache[w] = stemmer.stem(w)\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Fungsi apply per chunk (biar ga berat)\n",
    "def apply_in_chunks(series, func, chunk=2000):\n",
    "    out_chunks = []\n",
    "    for i in tqdm(range(0, len(series), chunk)):\n",
    "        out = series.iloc[i:i+chunk].apply(func)\n",
    "        out_chunks.append(out)\n",
    "    return pd.concat(out_chunks)\n",
    "\n",
    "# Terapkan ke kolom Narasi\n",
    "data['clean_text'] = apply_in_chunks(data['Narasi'].astype(str), clean_text, chunk=2000)\n",
    "\n",
    "print(\"âœ… Preprocessing selesai!\")\n",
    "print(data[['Narasi','clean_text','hoax']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21fa78ec-e205-4792-a9e8-7019a0f2b688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribusi y_train:\n",
      " hoax\n",
      "0    10066\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribusi y_test:\n",
      " hoax\n",
      "0    4314\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 4: TF-IDF + Train-Test Split =====\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TF-IDF dengan unigram, bigram, trigram\n",
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1,3),      # unigram + bigram + trigram\n",
    "    max_features=20000,     # jumlah fitur maksimal\n",
    "    sublinear_tf=True       # scaling TF\n",
    ")\n",
    "\n",
    "# ===== Cell 4: Split Data =====\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data['clean_text']\n",
    "y = data['hoax']\n",
    "\n",
    "# Stratified split supaya proporsi REAL/HOAX tetap seimbang di train & test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Distribusi y_train:\\n\", y_train.value_counts())\n",
    "print(\"\\nDistribusi y_test:\\n\", y_test.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49e14c97-b640-4544-8515-964b5d341fa2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'dpr minta jokowi turun tangan soal panas dingin hubung andika dudung anggota komisi i dpr fraksi pdip effendi simbolon minta presiden joko widodo turun tangan sikap isu tegang hubung panglima tni jenderal andika perkasa ksad jenderal dudung abdurrachman effendi harap isu kereta hubung dua justru jadi liar tengah masyarakat turut panas dingin hubung panglima tni bukan kali pertama presiden turun tangan jangan orang pikir tanda petik langsung cukup lama kata kompleks parlemen kamis effendi contoh isu kereta panglima tni jabat moeldoko ksad pimpin gatot nurmantyo khawatir kereta tubuh tni justru manfaat pihak luar galang kuat effendi harap tni segera laku evaluasi tengah isu sebut enggan bicara lebih jauh soal mungkin ubah sistem komando tubuh tni andai isu sebut tak segera selesai biar semua evaluasi kan pernah nama panglima angkat darat pernah pakai tongkat tuh aja sana poin enggak sana dulu kata kata isu sebut penting segera selesai sangkut baik tni kabar disharmoni hubung andika dudung belum ungkap effendi rapat komisi i tni senin sebut ego jenderal angkat darat rusak hubung senior junior dudung tak hadir rapat apa sih kemudian tahan ego ego bapak dua rusak tatanan hubung senior junior tni pak kata effendi baik andika maupun dudung ban kereta hubung dua dudung tegas internal tni solid kalau jadi friksi jadi beda dapat rasa semua lapang sama pangdam kasdam beda dapat kapolri wakapolri ksad panglima beda dapat biasa kata dudung acara bincang bangsa mabesad jakarta rabu thr pmg'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m mnb = MultinomialNB()\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mmnb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Prediksi di data test\u001b[39;00m\n\u001b[32m     13\u001b[39m y_pred = mnb.predict(X_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1466\u001b[39m     estimator._validate_params()\n\u001b[32m   1468\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1469\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1470\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1471\u001b[39m     )\n\u001b[32m   1472\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1473\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\naive_bayes.py:732\u001b[39m, in \u001b[36m_BaseDiscreteNB.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    711\u001b[39m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    712\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    713\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Fit Naive Bayes classifier according to X, y.\u001b[39;00m\n\u001b[32m    714\u001b[39m \n\u001b[32m    715\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    730\u001b[39m \u001b[33;03m        Returns the instance itself.\u001b[39;00m\n\u001b[32m    731\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m     X, y = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m     _, n_features = X.shape\n\u001b[32m    735\u001b[39m     labelbin = LabelBinarizer()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\naive_bayes.py:578\u001b[39m, in \u001b[36m_BaseDiscreteNB._check_X_y\u001b[39m\u001b[34m(self, X, y, reset)\u001b[39m\n\u001b[32m    576\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_check_X_y\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, reset=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    577\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Validate X and y in fit methods.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m578\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:650\u001b[39m, in \u001b[36mBaseEstimator._validate_data\u001b[39m\u001b[34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[39m\n\u001b[32m    648\u001b[39m         y = check_array(y, input_name=\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m, **check_y_params)\n\u001b[32m    649\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m650\u001b[39m         X, y = \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    651\u001b[39m     out = X, y\n\u001b[32m    653\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params.get(\u001b[33m\"\u001b[39m\u001b[33mensure_2d\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1301\u001b[39m, in \u001b[36mcheck_X_y\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1296\u001b[39m         estimator_name = _check_estimator_name(estimator)\n\u001b[32m   1297\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1298\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires y to be passed, but the target y is None\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1299\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1301\u001b[39m X = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1302\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1303\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1304\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1306\u001b[39m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1307\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1308\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1309\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1310\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1311\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1312\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1313\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1314\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1315\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1316\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1318\u001b[39m y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n\u001b[32m   1320\u001b[39m check_consistent_length(X, y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1012\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1010\u001b[39m         array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1011\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m         array = \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1014\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1015\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.format(array)\n\u001b[32m   1016\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomplex_warning\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:745\u001b[39m, in \u001b[36m_asarray_with_order\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    743\u001b[39m     array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m745\u001b[39m     array = \u001b[43mnumpy\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    747\u001b[39m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    748\u001b[39m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[32m    749\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m xp.asarray(array)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:1031\u001b[39m, in \u001b[36mSeries.__array__\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m    981\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    982\u001b[39m \u001b[33;03mReturn the values as a NumPy array.\u001b[39;00m\n\u001b[32m    983\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1028\u001b[39m \u001b[33;03m      dtype='datetime64[ns]')\u001b[39;00m\n\u001b[32m   1029\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1030\u001b[39m values = \u001b[38;5;28mself\u001b[39m._values\n\u001b[32m-> \u001b[39m\u001b[32m1031\u001b[39m arr = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(values.dtype, arr.dtype):\n\u001b[32m   1033\u001b[39m     arr = arr.view()\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: 'dpr minta jokowi turun tangan soal panas dingin hubung andika dudung anggota komisi i dpr fraksi pdip effendi simbolon minta presiden joko widodo turun tangan sikap isu tegang hubung panglima tni jenderal andika perkasa ksad jenderal dudung abdurrachman effendi harap isu kereta hubung dua justru jadi liar tengah masyarakat turut panas dingin hubung panglima tni bukan kali pertama presiden turun tangan jangan orang pikir tanda petik langsung cukup lama kata kompleks parlemen kamis effendi contoh isu kereta panglima tni jabat moeldoko ksad pimpin gatot nurmantyo khawatir kereta tubuh tni justru manfaat pihak luar galang kuat effendi harap tni segera laku evaluasi tengah isu sebut enggan bicara lebih jauh soal mungkin ubah sistem komando tubuh tni andai isu sebut tak segera selesai biar semua evaluasi kan pernah nama panglima angkat darat pernah pakai tongkat tuh aja sana poin enggak sana dulu kata kata isu sebut penting segera selesai sangkut baik tni kabar disharmoni hubung andika dudung belum ungkap effendi rapat komisi i tni senin sebut ego jenderal angkat darat rusak hubung senior junior dudung tak hadir rapat apa sih kemudian tahan ego ego bapak dua rusak tatanan hubung senior junior tni pak kata effendi baik andika maupun dudung ban kereta hubung dua dudung tegas internal tni solid kalau jadi friksi jadi beda dapat rasa semua lapang sama pangdam kasdam beda dapat kapolri wakapolri ksad panglima beda dapat biasa kata dudung acara bincang bangsa mabesad jakarta rabu thr pmg'"
     ]
    }
   ],
   "source": [
    "# ===== Cell 5: Training Multinomial Naive Bayes =====\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "# Inisialisasi model MNB\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "# Training\n",
    "mnb.fit(X_train, y_train)\n",
    "\n",
    "# Prediksi di data test\n",
    "y_pred = mnb.predict(X_test)\n",
    "\n",
    "# Evaluasi\n",
    "print(\"=== Evaluasi Model (MNB) ===\")\n",
    "print(\"Akurasi:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, labels=[0,1], target_names=[\"REAL\",\"HOAX\"]))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Tambahan: cek distribusi biar tau seimbang/tidak\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, labels=[0,1], target_names=[\"REAL\",\"HOAX\"], zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ed2fbfc-c2e4-49df-94ed-66e8c610b7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teks (potongan): Presiden Joko Widodo meresmikan proyek kereta cepat Jakartaâ€“Bandung \n",
      "    yang diharapkan memangkas w ...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     22\u001b[39m berita_uji = [\n\u001b[32m     23\u001b[39m     \u001b[38;5;66;03m# Real\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Presiden Joko Widodo meresmikan proyek kereta cepat Jakartaâ€“Bandung \u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     35\u001b[39m \u001b[33;03m    yang memiliki KTP elektronik tanpa syarat tambahan apapun.\"\"\"\u001b[39;00m\n\u001b[32m     36\u001b[39m ]\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m teks \u001b[38;5;129;01min\u001b[39;00m berita_uji:\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[43mprediksi_berita\u001b[49m\u001b[43m(\u001b[49m\u001b[43mteks\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mprediksi_berita\u001b[39m\u001b[34m(teks, model)\u001b[39m\n\u001b[32m     12\u001b[39m pred = model.predict(fitur)[\u001b[32m0\u001b[39m]\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTeks (potongan):\u001b[39m\u001b[33m\"\u001b[39m, teks[:\u001b[32m100\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mProbabilitas => REAL:\u001b[39m\u001b[33m\"\u001b[39m, probas[\u001b[32m0\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33m | HOAX:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mprobas\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPrediksi:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mHOAX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pred == \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mREAL\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m80\u001b[39m)\n",
      "\u001b[31mIndexError\u001b[39m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "# ===== Cell 6: Fungsi Prediksi Berita Tunggal =====\n",
    "\n",
    "def prediksi_berita(teks, model=mnb):\n",
    "    # Bersihkan teks\n",
    "    teks_clean = clean_text(teks)\n",
    "\n",
    "    # Transformasi ke TF-IDF\n",
    "    fitur = vectorizer.transform([teks_clean])\n",
    "\n",
    "    # Prediksi probabilitas\n",
    "    probas = model.predict_proba(fitur)[0]\n",
    "    pred = model.predict(fitur)[0]\n",
    "\n",
    "    print(\"Teks (potongan):\", teks[:100], \"...\")\n",
    "    print(\"Probabilitas => REAL:\", probas[0], \" | HOAX:\", probas[1])\n",
    "    print(\"Prediksi:\", \"HOAX\" if pred == 1 else \"REAL\")\n",
    "    print(\"-\"*80)\n",
    "    return \"HOAX\" if pred == 1 else \"REAL\"\n",
    "\n",
    "\n",
    "# ===== Tes dengan beberapa berita (real & hoax) =====\n",
    "berita_uji = [\n",
    "    # Real\n",
    "    \"\"\"Presiden Joko Widodo meresmikan proyek kereta cepat Jakartaâ€“Bandung \n",
    "    yang diharapkan memangkas waktu perjalanan menjadi hanya 45 menit.\"\"\",\n",
    "\n",
    "    \"\"\"Badan Meteorologi, Klimatologi, dan Geofisika (BMKG) mengeluarkan \n",
    "    peringatan dini terkait potensi hujan lebat di wilayah Jawa Barat.\"\"\",\n",
    "\n",
    "    # Hoax\n",
    "    \"\"\"Minum air rebusan kabel listrik disebut-sebut bisa menyembuhkan \n",
    "    penyakit jantung tanpa obat dokter. Pesan berantai ini menyebar di WhatsApp.\"\"\",\n",
    "\n",
    "    \"\"\"Pemerintah akan membagikan uang tunai Rp15 juta kepada semua warga \n",
    "    yang memiliki KTP elektronik tanpa syarat tambahan apapun.\"\"\"\n",
    "]\n",
    "\n",
    "for teks in berita_uji:\n",
    "    prediksi_berita(teks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de34fca2-46b6-4d1d-9265-6b60c1446ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 7: Simpan Model & Vectorizer =====\n",
    "import joblib\n",
    "\n",
    "# Simpan model dan vectorizer\n",
    "joblib.dump(mnb, \"model_mnb.pkl\")\n",
    "joblib.dump(vectorizer, \"vectorizer.pkl\")\n",
    "\n",
    "print(\"âœ… Model dan vectorizer berhasil disimpan ke file .pkl\")\n",
    "\n",
    "# Coba load ulang untuk tes\n",
    "model_loaded = joblib.load(\"model_mnb.pkl\")\n",
    "vectorizer_loaded = joblib.load(\"vectorizer.pkl\")\n",
    "\n",
    "# Tes prediksi pakai model yang udah di-load ulang\n",
    "sample_text = \"BMKG mengumumkan potensi hujan deras di wilayah Jabodetabek besok sore.\"\n",
    "prediksi_berita(sample_text, model=model_loaded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028646e2-5526-485f-b8bc-094adaa1bc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 8: Web App Flask untuk Deteksi Hoax =====\n",
    "from flask import Flask, request, render_template_string\n",
    "import joblib\n",
    "\n",
    "# Load model & vectorizer yang sudah disimpan\n",
    "model = joblib.load(\"model_mnb.pkl\")\n",
    "vectorizer = joblib.load(\"vectorizer.pkl\")\n",
    "\n",
    "# Inisialisasi Flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Template HTML sederhana (langsung di sini biar gampang tes)\n",
    "HTML_TEMPLATE = \"\"\"\n",
    "<!doctype html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Deteksi Berita Hoax</title>\n",
    "</head>\n",
    "<body>\n",
    "    <h2>ðŸ“° Deteksi Berita Hoax</h2>\n",
    "    <form method=\"POST\">\n",
    "        <textarea name=\"berita\" rows=\"10\" cols=\"80\" placeholder=\"Tempelkan berita di sini...\"></textarea><br><br>\n",
    "        <input type=\"submit\" value=\"Prediksi\">\n",
    "    </form>\n",
    "    {% if hasil %}\n",
    "        <h3>Hasil Prediksi: {{ hasil }}</h3>\n",
    "        <p>Probabilitas => REAL: {{ real }} | HOAX: {{ hoax }}</p>\n",
    "    {% endif %}\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Route utama\n",
    "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
    "def index():\n",
    "    hasil, real, hoax = None, None, None\n",
    "    if request.method == \"POST\":\n",
    "        teks = request.form[\"berita\"]\n",
    "        if teks.strip():\n",
    "            teks_clean = teks  # bisa tambahin clean_text(teks) kalau mau\n",
    "            fitur = vectorizer.transform([teks_clean])\n",
    "            probas = model.predict_proba(fitur)[0]\n",
    "            pred = model.predict(fitur)[0]\n",
    "            hasil = \"HOAX\" if pred == 1 else \"REAL\"\n",
    "            real, hoax = round(probas[0], 4), round(probas[1], 4)\n",
    "    return render_template_string(HTML_TEMPLATE, hasil=hasil, real=real, hoax=hoax)\n",
    "\n",
    "# Jalankan server Flask\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
